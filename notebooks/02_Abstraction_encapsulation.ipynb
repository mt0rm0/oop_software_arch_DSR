{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OOP 2: Abstraction and Encapsulation\n",
    "\n",
    "In this notebook, we'll explore the concepts of abstraction and encapsulation in Object-Oriented Programming (OOP) using Python. We'll illustrate these concepts with examples relevant to data science.\n",
    "\n",
    "## Table of Contents\n",
    "\n",
    "\n",
    "1. [Introduction to Abstraction](#1)\n",
    "2. [Abstraction in Python](#2)\n",
    "3. [Introduction to Encapsulation](#3)\n",
    "4. [Encapsulation in Python](#4)\n",
    "5. [Example: Data Processing Pipeline](#5)\n",
    "6. [Exercise: Build a different DataProcessor Class](#6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 1. Introduction to Abstraction <a id=\"1\"></a>\n",
    "\n",
    "Abstraction is the process of hiding the complex implementation details and showing only the essential features of an object. It helps to reduce complexity and allows the programmer to focus on interactions at a higher level.\n",
    "\n",
    "In data science, a common abstraction might be a DataProcessor class that abstracts away the details of reading, cleaning, and transforming data, providing simple methods to perform these tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 2. Abstraction in Python <a id=\"2\"></a>\n",
    "\n",
    "To implement abstraction in Python, we can use abstract classes and methods provided by the abc module.\n",
    "\n",
    "In this example, `DataProcessor` is an abstract class with abstract methods `read_data` and `process_data`. The `CSVDataProcessor` class provides concrete implementations of these methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataProcessor:\n",
    "    def read_data(self, source):\n",
    "        raise NotImplementedError\n",
    "    \n",
    "    def process_data(self):\n",
    "        pass\n",
    "\n",
    "class CSVDataProcessor(DataProcessor):\n",
    "    def read_data(self, source):\n",
    "        print(source)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NotImplementedError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNotImplementedError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m dp = CSVDataProcessor()\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[43mdp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread_data\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mdata.csv\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 3\u001b[39m, in \u001b[36mDataProcessor.read_data\u001b[39m\u001b[34m(self, source)\u001b[39m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mread_data\u001b[39m(\u001b[38;5;28mself\u001b[39m, source):\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m\n",
      "\u001b[31mNotImplementedError\u001b[39m: "
     ]
    }
   ],
   "source": [
    "dp = CSVDataProcessor()\n",
    "dp.read_data(\"data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from abc import ABC, abstractmethod\n",
    "\n",
    "class DataProcessor(ABC):\n",
    "    @abstractmethod\n",
    "    def read_data(self, source):\n",
    "        pass\n",
    "    \n",
    "    @abstractmethod\n",
    "    def process_data(self):\n",
    "        pass\n",
    "\n",
    "class CSVDataProcessor(DataProcessor):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Can't instantiate abstract class CSVDataProcessor without an implementation for abstract methods 'process_data', 'read_data'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m dp = \u001b[43mCSVDataProcessor\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      2\u001b[39m dp.read_data(\u001b[33m\"\u001b[39m\u001b[33mdata.csv\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mTypeError\u001b[39m: Can't instantiate abstract class CSVDataProcessor without an implementation for abstract methods 'process_data', 'read_data'"
     ]
    }
   ],
   "source": [
    "dp = CSVDataProcessor()\n",
    "dp.read_data(\"data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from abc import ABC, abstractmethod\n",
    "\n",
    "class DataProcessor(ABC):\n",
    "    @abstractmethod\n",
    "    def read_data(self, source):\n",
    "        pass\n",
    "    \n",
    "    @abstractmethod\n",
    "    def process_data(self):\n",
    "        pass\n",
    "\n",
    "class CSVDataProcessor(DataProcessor):\n",
    "    def read_data(self, source):\n",
    "        # Implementation for reading CSV data\n",
    "        pass\n",
    "    \n",
    "    def process_data(self):\n",
    "        # Implementation for processing CSV data\n",
    "        pass\n",
    "\n",
    "class TXTDataProcessor:\n",
    "    def read_data(self, source):\n",
    "        # Implementation for reading CSV data\n",
    "        pass\n",
    "    \n",
    "    def process_data(self):\n",
    "        # Implementation for processing CSV data\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dp = CSVDataProcessor()\n",
    "dp.read_data(\"data.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 3. Introduction to Encapsulation <a id=\"3\"></a>\n",
    "\n",
    "Encapsulation is the bundling of data and methods that operate on that data within a single unit (class), and restricting access to some of the object's components. This means that the internal representation of an object is hidden from the outside.\n",
    "\n",
    "Encapsulation ensures that the data within a DataProcessor object can only be modified through specific methods, ensuring data integrity and preventing unintended interference."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "## 4. Encapsulation in Python <a id=\"4\"></a>\n",
    "\n",
    "**In Python, encapsulation is more about convention than enforcement.** Python does not have true private variables like some other languages. Instead, it uses naming conventions to indicate the intended visibility of attributes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Single Underscore (_)\n",
    "\n",
    "A single underscore before a method or attribute name is a convention indicating that it is intended for internal use only. It signals to other programmers that this is a \"protected\" member of the class and should not be accessed directly from outside the class. However, it does not enforce this restriction; it is just a convention.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Double Underscore (__)\n",
    "\n",
    "A double underscore before a method or attribute name triggers name mangling, which means that the interpreter changes the name of the method or attribute to include the class name. This makes it harder to accidentally override or access the method or attribute from outside the class. It's a way to ensure that the method or attribute is private and intended to be used only within the class itself."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example, `_data` is a protected attribute, `_clean_data` is a protected method, and `__load_data` is a private method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data from train.csv\n"
     ]
    }
   ],
   "source": [
    "class DataProcessor:\n",
    "    def __init__(self):\n",
    "        self._data = None  # Protected attribute\n",
    "    \n",
    "    def read_data(self, source):\n",
    "        self.__load_data(source)  # Private method\n",
    "    \n",
    "    def process_data(self):\n",
    "        # Public method for processing data\n",
    "        pass\n",
    "    \n",
    "    def _clean_data(self):\n",
    "        # Protected method for cleaning data\n",
    "        pass\n",
    "    \n",
    "    def __load_data(self, source):\n",
    "        # Private method for loading data\n",
    "        self._data = \"Data from \" + source\n",
    "        \n",
    "# Using the DataProcessor class\n",
    "processor = DataProcessor()\n",
    "processor.read_data(\"train.csv\")\n",
    "print(processor._data)  # Accessing protected attribute\n",
    "# processor.__load_data(\"example.csv\") # Raises AttributeError\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "processor._DataProcessor__load_data(\"train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "mappingproxy({'__module__': '__main__',\n",
       "              '__firstlineno__': 1,\n",
       "              '__init__': <function __main__.DataProcessor.__init__(self)>,\n",
       "              'read_data': <function __main__.DataProcessor.read_data(self, source)>,\n",
       "              'process_data': <function __main__.DataProcessor.process_data(self)>,\n",
       "              '_clean_data': <function __main__.DataProcessor._clean_data(self)>,\n",
       "              '_DataProcessor__load_data': <function __main__.DataProcessor.__load_data(self, source)>,\n",
       "              '__static_attributes__': ('_data',),\n",
       "              '__dict__': <attribute '__dict__' of 'DataProcessor' objects>,\n",
       "              '__weakref__': <attribute '__weakref__' of 'DataProcessor' objects>,\n",
       "              '__doc__': None})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DataProcessor.__dict__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "<br>\n",
    "\n",
    "><details>\n",
    "><summary>Curious about the underscores in Python?</summary>\n",
    "> \n",
    "> You can find more info [here](https://realpython.com/python-double-underscore/#double-leading-underscore-in-classes-pythons-name-mangling).\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 5. Example: Data Processing Pipeline <a id=\"5\"></a>\n",
    "\n",
    "Let's create a more comprehensive example of a data processing pipeline that uses both abstraction and encapsulation.\n",
    "\n",
    "**Step-by-Step Example**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    age  salary  processed\n",
      "0  25.0   50000       True\n",
      "1  30.0   60000       True\n",
      "2  35.0   70000       True\n",
      "3  40.0   80000       True\n"
     ]
    }
   ],
   "source": [
    "from abc import ABC, abstractmethod\n",
    "import pandas as pd\n",
    "\n",
    "class DataProcessor(ABC):\n",
    "    def __init__(self):\n",
    "        self._data = None\n",
    "    \n",
    "    @abstractmethod\n",
    "    def read_data(self, source):\n",
    "        pass\n",
    "    \n",
    "    @abstractmethod\n",
    "    def process_data(self):\n",
    "        pass\n",
    "    \n",
    "    def get_data(self):\n",
    "        return self._data\n",
    "\n",
    "class CSVDataProcessor(DataProcessor):\n",
    "    def read_data(self, source):\n",
    "        self._data = pd.read_csv(source)\n",
    "    \n",
    "    def process_data(self):\n",
    "        self._clean_data()\n",
    "        self._transform_data()\n",
    "    \n",
    "    def _clean_data(self):\n",
    "        self._data.dropna(inplace=True)\n",
    "    \n",
    "    def _transform_data(self):\n",
    "        self._data['processed'] = True\n",
    "\n",
    "# Using the CSVDataProcessor class\n",
    "processor = CSVDataProcessor()\n",
    "processor.read_data(\"sample.csv\")\n",
    "processor.process_data()\n",
    "print(processor.get_data().head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Explanation**\n",
    "\n",
    "1. **Abstract Class**: `DataProcessor` is an abstract class with abstract methods `read_data` and `process_data`.\n",
    "\n",
    "2. **Concrete Class**: `CSVDataProcessor` provides concrete implementations of the abstract methods and defines protected methods `_clean_data` and `_transform_data`.\n",
    "\n",
    "3. **Encapsulation**: Protected attributes and methods ensure that the data is manipulated in a controlled manner.\n",
    "\n",
    "4. **Usage**: An instance of `CSVDataProcessor` is created, data is read from a CSV file, processed, and the processed data is accessed using a public method."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 6. Exercise: Build a different DataProcessor Class <a id=\"6\"></a>\n",
    "\n",
    "Create a subclass JSONDataProcessor. The JSONDataProcessor will be designed to read and process JSON data. Implement the class with the following functionalities:\n",
    "\n",
    "### Requirements\n",
    "\n",
    "- Subclass `JSONDataProcessor`\n",
    "\n",
    "  - It inherits from `DataProcessor`\n",
    "  \n",
    "  - Methods:\n",
    "    - `read_data(source)`: Reads JSON data from the specified source.\n",
    "\n",
    "    - `process_data()`: Calls _clean_data() and _transform_data() to process the data.\n",
    "\n",
    "    - `_clean_data()`: Handles data cleaning (e.g., removing missing values).\n",
    "    \n",
    "    - `_transform_data()`: Handles data transformation (e.g., adding a new column)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n",
    "class JSONDataProcessor(DataProcessor):\n",
    "    def __init__(self, pipeline_name):\n",
    "        self.pipeline = pipeline_name\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "><details>\n",
    "><summary>Do you need some help?</summary>\n",
    "> \n",
    "> Here is a working solution\n",
    "> ```python\n",
    "> class JSONDataProcessor(DataProcessor):\n",
    ">    def read_data(self, source):\n",
    ">        self._data = pd.read_json(source)\n",
    ">    \n",
    ">    def process_data(self):\n",
    ">        self._clean_data()\n",
    ">        self._transform_data()\n",
    ">    \n",
    ">    def _clean_data(self):\n",
    ">        self._data.dropna(inplace=True)\n",
    ">   \n",
    ">    def _transform_data(self):\n",
    ">        self._data['processed'] = True\n",
    "> ```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try now if your code worked as expected. Run the following cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using the CSVDataProcessor class\n",
    "processor = JSONDataProcessor()\n",
    "processor.read_data(\"sample.json\")\n",
    "processor.process_data()\n",
    "print(processor.get_data().head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(self, source: str) -> str:\n",
    "    \"\"\"Reads data from the specified source.\"\"\"\n",
    "    return source\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "oop-software-arch-dsr",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
